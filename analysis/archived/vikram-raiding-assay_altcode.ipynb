{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_trail_map(tracks, video_file, output_path, trail_props, antennal_pose_markers, body_pose_markers, dont_use_flags=True, remove_single_frame_tracks=False):\n",
    "    '''\n",
    "    Generates a trail map video from the cleaned data, using the provided trail properties and antennal pose markers.\n",
    "    '''\n",
    "    # generate the cleaned data\n",
    "    cleaned_data = tracks.copy()\n",
    "    # remove flagged frames\n",
    "    if dont_use_flags:\n",
    "        cleaned_data = [track[track['pose_flag'] == 0].reset_index(drop=True) for track in cleaned_data]\n",
    "    # remove single frame tracks\n",
    "    if remove_single_frame_tracks:\n",
    "        cleaned_data = [track[track['single_frame'] == 0].reset_index(drop=True) for track in cleaned_data]\n",
    "\n",
    "    cleaned_data = pd.concat(cleaned_data).sort_values(['frame_idx', 'segment']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Get average body length\n",
    "    x_diff = cleaned_data[body_pose_markers[0] + '.x'] - cleaned_data[body_pose_markers[1] + '.x']\n",
    "    y_diff = cleaned_data[body_pose_markers[0] + '.y'] - cleaned_data[body_pose_markers[1] + '.y']\n",
    "    body_length = np.nanmean(np.sqrt(x_diff**2 + y_diff**2))\n",
    "\n",
    "    # Set the spread of the trail in pixels\n",
    "    sd = trail_props['spread'] * body_length\n",
    "\n",
    "    # Get the maximum frame index\n",
    "    max_frame = int(cleaned_data['frame_idx'].max())\n",
    "\n",
    "    # Create the empty trail map\n",
    "    trail_map = np.zeros(DIMENSION)\n",
    "\n",
    "    # Set up video reader\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    # Set up video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, FRAME_RATE, (DIMENSION[0], DIMENSION[1]), isColor=False)\n",
    "\n",
    "    # Loop over the frames\n",
    "    for frame in tqdm(range(max_frame//20)):\n",
    "\n",
    "        # move the video to the frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, back = cap.read()\n",
    "        if not ret:\n",
    "            print('Error reading frame')\n",
    "            break\n",
    "        # convert to grayscale\n",
    "        back = cv2.cvtColor(back, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Decay the trail map\n",
    "        trail_map = trail_map * trail_props['decay'] ** (1 / FRAME_RATE)\n",
    "        \n",
    "        # Get the tracks at the current frame\n",
    "        current_tracks = cleaned_data[cleaned_data['frame_idx'] == frame]\n",
    "        \n",
    "        # Get the position of the source\n",
    "        source_x = current_tracks[trail_props['source'] + '.x'].values\n",
    "        source_y = current_tracks[trail_props['source'] + '.y'].values\n",
    "\n",
    "        # Add a 2D Gaussian to the trail map\n",
    "        for x, y in zip(source_x, source_y):\n",
    "            # skip if the position is nan\n",
    "            if np.isnan(x) or np.isnan(y):\n",
    "                continue\n",
    "            addition = norm.pdf(np.arange(DIMENSION[0]), x, sd)[:, None] * norm.pdf(np.arange(DIMENSION[1]), y, sd)\n",
    "            # Normalize the addition\n",
    "            addition = addition / addition.max()\n",
    "            trail_map += addition\n",
    "\n",
    "        # Get the indices of the cleaned data at the current frame\n",
    "        indices = cleaned_data[cleaned_data['frame_idx'] == frame].index\n",
    "        \n",
    "        # Get the position of the antennae at the current frame\n",
    "        antennae_x = cleaned_data.loc[indices, [marker + '.x' for marker in antennal_pose_markers]].values\n",
    "        antennae_y = cleaned_data.loc[indices, [marker + '.y' for marker in antennal_pose_markers]].values\n",
    "\n",
    "        # Loop over the indices and add the trail value to the cleaned data\n",
    "        f = interp2d(np.arange(DIMENSION[0]), np.arange(DIMENSION[1]), trail_map)\n",
    "        for i, idx in enumerate(indices):\n",
    "            for j, marker in enumerate(antennal_pose_markers):\n",
    "                if np.isnan(antennae_x[i, j]) or np.isnan(antennae_y[i, j]):\n",
    "                    continue\n",
    "                x = int(np.clip(antennae_x[i, j], 0, DIMENSION[0] - 1))\n",
    "                y = int(np.clip(antennae_y[i, j], 0, DIMENSION[1] - 1))\n",
    "                # Interpolate the value of the trail map at the position of the antennae\n",
    "                cleaned_data.loc[idx, marker + '.trail'] = trail_map[x, y]\n",
    "                cleaned_data.loc[idx, marker + '.trail_normalized'] = (trail_map[x, y] - trail_map.min()) / (trail_map.max() - trail_map.min())\n",
    "\n",
    "        # Write the frame to the video in grayscale\n",
    "        frame_to_write = (trail_map - trail_map.min()) / (trail_map.max() - trail_map.min()) * 255\n",
    "        frame_to_write = frame_to_write.astype(np.uint8)\n",
    "\n",
    "        # overlay back with the trail map\n",
    "        frame_to_write = cv2.addWeighted(back, 0.5, frame_to_write, 0.5, 0)\n",
    "\n",
    "\n",
    "        # Draw the ants on the frame (all pose markers)\n",
    "        for idx in indices:\n",
    "            # define the variables as nan\n",
    "            petiole = (np.nan, np.nan)\n",
    "            tip_of_head = (np.nan, np.nan)\n",
    "            ovipositor = (np.nan, np.nan)\n",
    "            antennaL = (np.nan, np.nan)\n",
    "            antennaR = (np.nan, np.nan)\n",
    "            \n",
    "            # Get the positions of the pose markers\n",
    "            try:\n",
    "                petiole = (int(cleaned_data.loc[idx, 'petiole.y']), int(cleaned_data.loc[idx, 'petiole.x']))\n",
    "                frame_to_write = cv2.circle(frame_to_write, petiole, 5, 255, -1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                tip_of_head = (int(cleaned_data.loc[idx, 'tip_of_head.y']), int(cleaned_data.loc[idx, 'tip_of_head.x']))\n",
    "                frame_to_write = cv2.circle(frame_to_write, tip_of_head, 5, 255, -1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                ovipositor = (int(cleaned_data.loc[idx, 'ovipositor.y']), int(cleaned_data.loc[idx, 'ovipositor.x']))\n",
    "                frame_to_write = cv2.circle(frame_to_write, ovipositor, 5, 255, -1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                antennaL = (int(cleaned_data.loc[idx, 'antennaL.y']), int(cleaned_data.loc[idx, 'antennaL.x']))\n",
    "                size = int((cleaned_data.loc[idx, 'antennaL.trail'] - trail_map.min()) / (trail_map.max() - trail_map.min()) * 30)\n",
    "                frame_to_write = cv2.circle(frame_to_write, antennaL, size, 255, -1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                antennaR = (int(cleaned_data.loc[idx, 'antennaR.y']), int(cleaned_data.loc[idx, 'antennaR.x']))\n",
    "                size = int((cleaned_data.loc[idx, 'antennaR.trail'] - trail_map.min()) / (trail_map.max() - trail_map.min()) * 30)\n",
    "                frame_to_write = cv2.circle(frame_to_write, antennaR, size, 255, -1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Draw lines connecting pose markers\n",
    "            try:\n",
    "                frame_to_write = cv2.line(frame_to_write, petiole, tip_of_head, 255, 1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                frame_to_write = cv2.line(frame_to_write, petiole, ovipositor, 255, 1)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "            try:\n",
    "                frame_to_write = cv2.line(frame_to_write, tip_of_head, antennaL, 255, 1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                frame_to_write = cv2.line(frame_to_write, tip_of_head, antennaR, 255, 1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # draw an arrow from the higher antennae to the lower antennae to indicate direction\n",
    "            try:\n",
    "                offset = 30\n",
    "                # shift the points to the center of the ant\n",
    "                petiole = (int(cleaned_data.loc[idx, 'petiole.y']), int(cleaned_data.loc[idx, 'petiole.x']))\n",
    "                tip_of_head = (int(cleaned_data.loc[idx, 'tip_of_head.y']), int(cleaned_data.loc[idx, 'tip_of_head.x']))\n",
    "                body_axis_unit_vector = np.array([tip_of_head[0] - petiole[0], tip_of_head[1] - petiole[1]])\n",
    "                body_axis_unit_vector = body_axis_unit_vector / np.linalg.norm(body_axis_unit_vector)\n",
    "\n",
    "                # get the antennae positions by shifting them to the center of the ant\n",
    "                antennaL = (int(cleaned_data.loc[idx, 'antennaL.y']), int(cleaned_data.loc[idx, 'antennaL.x']))\n",
    "                antennaR = (int(cleaned_data.loc[idx, 'antennaR.y']), int(cleaned_data.loc[idx, 'antennaR.x']))\n",
    "                # move point along the body axis\n",
    "                antennaL = (antennaL[0] + int(body_axis_unit_vector[0] * offset), antennaL[1] + int(body_axis_unit_vector[1] * offset))\n",
    "                antennaR = (antennaR[0] + int(body_axis_unit_vector[0] * offset), antennaR[1] + int(body_axis_unit_vector[1] * offset))\n",
    "\n",
    "                # draw the arrow for antennal difference\n",
    "                if abs(cleaned_data.loc[idx, 'antennaR.trail_normalized'] - cleaned_data.loc[idx, 'antennaL.trail_normalized']) > 1e-3:\n",
    "                    if cleaned_data.loc[idx, 'antennaR.trail_normalized'] > cleaned_data.loc[idx, 'antennaL.trail_normalized']:\n",
    "                        frame_to_write = cv2.arrowedLine(frame_to_write, antennaL, antennaR, 255, 10, tipLength=0.5)\n",
    "                        # write the text\n",
    "                        frame_to_write = cv2.putText(frame_to_write, f'{cleaned_data.loc[idx, \"antennaR.trail_normalized\"] - cleaned_data.loc[idx, \"antennaL.trail_normalized\"]:.2f}', antennaL, cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2, cv2.LINE_AA)\n",
    "                    else:\n",
    "                        frame_to_write = cv2.arrowedLine(frame_to_write, antennaR, antennaL, 255, 10, tipLength=0.5)\n",
    "                        # write the text\n",
    "                        frame_to_write = cv2.putText(frame_to_write, f'{cleaned_data.loc[idx, \"antennaR.trail_normalized\"] - cleaned_data.loc[idx, \"antennaL.trail_normalized\"]:.2f}', antennaL, cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2, cv2.LINE_AA)\n",
    "\n",
    "                # shift the points another 10 pixels along the body axis\n",
    "                antennaL = (antennaL[0] + int(body_axis_unit_vector[0] * offset), antennaL[1] + int(body_axis_unit_vector[1] * offset))\n",
    "                antennaR = (antennaR[0] + int(body_axis_unit_vector[0] * offset), antennaR[1] + int(body_axis_unit_vector[1] * offset))\n",
    "\n",
    "                # draw the arrow for average future turn direction\n",
    "                # verify that the average future turn direction is not nan or 0\n",
    "                if not np.isnan(cleaned_data.loc[idx, 'average_future_turn_direction']) and cleaned_data.loc[idx, 'average_future_turn_direction'] != 0:\n",
    "                    if cleaned_data.loc[idx, 'average_future_turn_direction'] > 0:\n",
    "                        frame_to_write = cv2.arrowedLine(frame_to_write, antennaR, antennaL, 0, 10, tipLength=0.5)\n",
    "                        # write the text\n",
    "                        frame_to_write = cv2.putText(frame_to_write, f'{cleaned_data.loc[idx, \"average_future_turn_direction\"]:.2f}', antennaR, cv2.FONT_HERSHEY_SIMPLEX, 1, 0, 2, cv2.LINE_AA)\n",
    "                    else:\n",
    "                        frame_to_write = cv2.arrowedLine(frame_to_write, antennaL, antennaR, 0, 10, tipLength=0.5)\n",
    "                        # write the text\n",
    "                        frame_to_write = cv2.putText(frame_to_write, f'{cleaned_data.loc[idx, \"average_future_turn_direction\"]:.2f}', antennaL, cv2.FONT_HERSHEY_SIMPLEX, 1, 0, 2, cv2.LINE_AA)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Write the frame to the video\n",
    "        out.write(frame_to_write.astype(np.uint8))\n",
    "\n",
    "    # Release the video writer\n",
    "    out.release()\n",
    "\n",
    "    # Release the video reader\n",
    "    cap.release()\n",
    "\n",
    "    # convert back to tracks by segment number\n",
    "    tracks = []\n",
    "    for segment in cleaned_data['segment'].unique():\n",
    "        track = cleaned_data[cleaned_data['segment'] == segment].copy()\n",
    "        tracks.append(track)\n",
    "    return tracks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b4df9ece5f43c4801dbe5ea84c9db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.predicted_preclean.006_2018_05_25_19_58_cam_6_3.analysis.csv: Trail map generated\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21addf2d2244b0b925a877742385889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.predicted_preclean.004_2018_05_25_19_58_cam_5_2.analysis.csv: Trail map generated\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e443be46b274f9581b2ce501de2397a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.predicted_preclean.003_2018_05_25_19_58_cam_4_3.analysis.csv: Trail map generated\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c1fa3a71874f7284e3647ba76b10b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m trail_props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_of_head.antennaL.pose_distance_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m database[data_file][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_of_head.antennaL.pose_distance_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m trail_props[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_of_head.antennaR.pose_distance_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m database[data_file][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_of_head.antennaR.pose_distance_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m tracks \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_trail_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrail_props\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantennal_pose_markers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_pose_markers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# save the trail map path\u001b[39;00m\n\u001b[1;32m     23\u001b[0m database[data_file][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrail_map\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m output_path\n",
      "Cell \u001b[0;32mIn[19], line 42\u001b[0m, in \u001b[0;36mestimate_trail_map\u001b[0;34m(tracks, video_file, output_path, trail_props, antennal_pose_markers, body_pose_markers, dont_use_flags, remove_single_frame_tracks)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Loop over the frames\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(max_frame\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m20\u001b[39m)):\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# move the video to the frame\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Read the frame\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     ret, back \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "trail_props = {\n",
    "    'source': 'ovipositor',\n",
    "    'spread': 0.25,\n",
    "    'decay': 1,\n",
    "}\n",
    "antennal_pose_markers = ['antennaL', 'antennaR']\n",
    "body_pose_markers = ['ovipositor', 'tip_of_head']\n",
    "\n",
    "# estimate the trail map for all videos and also save the trail map path\n",
    "for data_file in list(database.keys()):\n",
    "    video_file = os.path.join(raw_video_folder, data_file.split('.')[2][4:] + '.mp4')\n",
    "\n",
    "    output_path = os.path.join(data_folder, data_file.replace('.csv', '_trail_map.mp4'))\n",
    "    tracks = database[data_file]['tracks']\n",
    "    # add pose distance threshold to trail props\n",
    "    trail_props['tip_of_head.petiole.pose_distance_threshold'] = database[data_file]['tip_of_head.petiole.pose_distance_threshold']\n",
    "    trail_props['petiole.ovipositor.pose_distance_threshold'] = database[data_file]['petiole.ovipositor.pose_distance_threshold']\n",
    "    trail_props['tip_of_head.antennaL.pose_distance_threshold'] = database[data_file]['tip_of_head.antennaL.pose_distance_threshold']\n",
    "    trail_props['tip_of_head.antennaR.pose_distance_threshold'] = database[data_file]['tip_of_head.antennaR.pose_distance_threshold']\n",
    "    tracks = estimate_trail_map(tracks, video_file, output_path, trail_props, antennal_pose_markers, body_pose_markers)\n",
    "    # save the trail map path\n",
    "    database[data_file]['trail_map'] = output_path\n",
    "    # save the tracks\n",
    "    database[data_file]['tracks'] = tracks\n",
    "    print(f'{data_file}: Trail map generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get centroid distance matrix\n",
    "def get_centroid_distance_matrix(tracks):\n",
    "    '''\n",
    "    Get the centroid distance matrix for the tracks (end of one track to start of another)\n",
    "    '''\n",
    "    # get the number of tracks\n",
    "    n_tracks = len(tracks)\n",
    "    # create an empty distance matrix\n",
    "    distance_matrix = np.zeros((n_tracks, n_tracks))\n",
    "    # calculate the distance between each pair of tracks\n",
    "    for i in range(n_tracks):\n",
    "        for j in range(n_tracks):\n",
    "            if i == j:\n",
    "                distance_matrix[i, j] = np.inf\n",
    "            distance_matrix[i, j] = distance.euclidean(tracks[i].iloc[-1][['centroid.x', 'centroid.y']].values, tracks[j].iloc[0][['centroid.x', 'centroid.y']].values)\n",
    "    return distance_matrix\n",
    "\n",
    "# get the time difference matrix\n",
    "def get_time_difference_matrix(tracks):\n",
    "    '''\n",
    "    Get the time difference matrix for the tracks (end of one track to start of another)\n",
    "    '''\n",
    "    # get the number of tracks\n",
    "    n_tracks = len(tracks)\n",
    "    # create an empty time difference matrix\n",
    "    time_matrix = np.zeros((n_tracks, n_tracks))\n",
    "    # calculate the time difference between each pair of tracks\n",
    "    for i in range(n_tracks):\n",
    "        for j in range(n_tracks):\n",
    "            time_matrix[i, j] = tracks[j].iloc[0]['time'] - tracks[i].iloc[-1]['time']\n",
    "            # if the time difference is negative, set it to infinity\n",
    "            if time_matrix[i, j] < 0:\n",
    "                time_matrix[i, j] = np.inf\n",
    "    return time_matrix\n",
    "\n",
    "# get the cost matrix\n",
    "def get_cost_matrix(tracks, distance_limit=1, time_limit=0.5, body_pose_markers=['ovipositor', 'tip_of_head']):\n",
    "    '''\n",
    "    Get the cost matrix for the tracks (end of one track to start of another)\n",
    "    '''\n",
    "    # get the number of tracks\n",
    "    n_tracks = len(tracks)\n",
    "    # get the average maximum body length\n",
    "    body_lengths = []\n",
    "    for track in tracks:\n",
    "        x_diff = track[body_pose_markers[1] + '.x'] - track[body_pose_markers[0] + '.x']\n",
    "        y_diff = track[body_pose_markers[1] + '.y'] - track[body_pose_markers[0] + '.y']\n",
    "        body_lengths.append(np.nanmax(np.sqrt(x_diff**2 + y_diff**2)))\n",
    "    body_length = np.nanmean(body_lengths)\n",
    "    # convert the distance limit to pixels\n",
    "    distance_limit = distance_limit * body_length\n",
    "    # create an empty cost matrix\n",
    "    cost_matrix = np.zeros((n_tracks, n_tracks))\n",
    "    # get the centroid distance matrix\n",
    "    distance_matrix = get_centroid_distance_matrix(tracks)\n",
    "    # get the time difference matrix\n",
    "    time_matrix = get_time_difference_matrix(tracks)\n",
    "    # calculate the cost matrix\n",
    "    for i in range(n_tracks):\n",
    "        for j in range(n_tracks):\n",
    "            if distance_matrix[i, j] < distance_limit and time_matrix[i, j] < time_limit:\n",
    "                cost_matrix[i, j] = distance_matrix[i, j] + time_matrix[i, j]\n",
    "            else:\n",
    "                cost_matrix[i, j] = np.inf\n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cost matrix for the tracks of the first video\n",
    "cost_matrix = get_cost_matrix(database[list(database.keys())[0]]['tracks'])\n",
    "# plot the cost matrix\n",
    "plt.imshow(cost_matrix, cmap='cool')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Track')\n",
    "plt.ylabel('Track')\n",
    "plt.title('Cost matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 3), (3, 4), (8, 9), (10, 41), (12, 60), (21, 22), (30, 31), (32, 44), (35, 51), (43, 44), (47, 48), (50, 31), (51, 52), (77, 78), (78, 79), (89, 90), (90, 91), (95, 96), (101, 102), (107, 108), (110, 111), (116, 117), (117, 118), (129, 130), (133, 146), (142, 138), (145, 146)]\n"
     ]
    }
   ],
   "source": [
    "# for each track, get the best matching track to find any sequential tracks\n",
    "matches = []\n",
    "for i in range(cost_matrix.shape[0]):\n",
    "    j = np.argmin(cost_matrix[i])\n",
    "    if cost_matrix[i, j] < np.inf:\n",
    "        matches.append((i, j))\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
